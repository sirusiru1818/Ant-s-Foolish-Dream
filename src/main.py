"""FastAPI ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
from datetime import datetime
from pathlib import Path
import uvicorn
import os
import csv
import json

from src.config import settings
from src.local_storage import LocalStorageService
from src.openai_service import OpenAIService
from src.local_ml_service import LocalMLService

# ML ì„œë¹„ìŠ¤ëŠ” ì„ íƒì‚¬í•­ì´ë¯€ë¡œ ì§€ì—° ë¡œë”©
ml_service = None
try:
    from src.ml_service import MLService
    ml_service = MLService()
except ImportError as e:
    print(f"ML ì„œë¹„ìŠ¤ ëª¨ë“ˆì„ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ì„ íƒì‚¬í•­): {e}")
    ml_service = None
except Exception as e:
    print(f"ML ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨ (ì„ íƒì‚¬í•­): {e}")
    ml_service = None


app = FastAPI(
    title="ì£¼ì‹ ì„±í–¥ ë¶„ì„ ë° ì¢…ëª© ì¶”ì²œ ì„œë¹„ìŠ¤",
    description="Azure ì„œë¹„ìŠ¤ë¥¼ í™œìš©í•œ ì£¼ì‹ ë¶„ì„ ë° ì¶”ì²œ API",
    version="1.0.0"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì •ì  íŒŒì¼ ì„œë¹™ (í”„ë¡ íŠ¸ì—”ë“œ)
static_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), "static")
if os.path.exists(static_dir):
    app.mount("/static", StaticFiles(directory=static_dir), name="static")

@app.get("/")
async def read_root():
    """ë£¨íŠ¸ ê²½ë¡œì—ì„œ í”„ë¡ íŠ¸ì—”ë“œ ì œê³µ"""
    static_file = os.path.join(static_dir, "index.html")
    if os.path.exists(static_file):
        return FileResponse(static_file)
    return {
        "message": "ì£¼ì‹ ì„±í–¥ ë¶„ì„ ë° ì¢…ëª© ì¶”ì²œ ì„œë¹„ìŠ¤",
        "version": "1.0.0",
        "status": "running",
        "docs": "/docs"
    }

@app.get("/details")
async def read_details():
    """ëª¨ë¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í˜ì´ì§€ ì œê³µ"""
    details_file = os.path.join(static_dir, "details.html")
    if os.path.exists(details_file):
        return FileResponse(details_file)
    raise HTTPException(status_code=404, detail="Details page not found")

# ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ data í´ë”ì— ì €ì¥
project_root = Path(__file__).parent.parent
data_dir = project_root / "data"
local_storage = LocalStorageService(base_dir=str(data_dir))
local_ml_service = LocalMLService(models_dir=str(data_dir / "models"))
openai_service = None

try:
    if settings.azure_openai_endpoint and settings.azure_openai_api_key:
        openai_service = OpenAIService()
    else:
        print("âš ï¸  Azure OpenAI ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤. ë¶„ì„ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
except Exception as e:
    print(f"âš ï¸  OpenAI ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")


# Pydantic ëª¨ë¸
class StockData(BaseModel):
    name: str
    price: float
    news: Optional[str] = None
    additional_info: Optional[Dict[str, Any]] = None


class UserPreference(BaseModel):
    risk_tolerance: str = "ë³´í†µ"  # ë‚®ìŒ, ë³´í†µ, ë†’ìŒ
    investment_amount: Optional[float] = None
    investment_period: Optional[str] = None
    interests: Optional[List[str]] = None


class AnalysisRequest(BaseModel):
    stock_data: StockData
    save_to_blob: bool = True


class RecommendationRequest(BaseModel):
    user_preference: UserPreference
    save_to_blob: bool = True


# API ì—”ë“œí¬ì¸íŠ¸
@app.get("/api")
async def api_info():
    """API ì •ë³´ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "message": "ì£¼ì‹ ì„±í–¥ ë¶„ì„ ë° ì¢…ëª© ì¶”ì²œ ì„œë¹„ìŠ¤",
        "version": "1.0.0",
        "status": "running",
        "endpoints": {
            "analyze": "/api/analyze",
            "recommend": "/api/recommend",
            "storage_list": "/api/storage/list",
            "docs": "/docs"
        }
    }


@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}


@app.post("/api/analyze")
async def analyze_stock(request: AnalysisRequest):
    """
    ì£¼ì‹ ì„±í–¥ ë¶„ì„
    
    Args:
        request: ë¶„ì„ ìš”ì²­ ë°ì´í„°
        
    Returns:
        ë¶„ì„ ê²°ê³¼
    """
    if not openai_service:
        raise HTTPException(status_code=503, detail="OpenAI ì„œë¹„ìŠ¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— Azure OpenAI ì„¤ì •ì„ ì¶”ê°€í•˜ì„¸ìš”.")
    
    try:
        # OpenAIë¥¼ í†µí•œ ì„±í–¥ ë¶„ì„
        stock_dict = request.stock_data.dict()
        analysis_result = openai_service.analyze_stock_sentiment(stock_dict)
        
        if not analysis_result:
            raise HTTPException(status_code=500, detail="ë¶„ì„ ì‹¤íŒ¨")
        
        # ê²°ê³¼ ì €ì¥
        result_data = {
            "stock_name": request.stock_data.name,
            "analysis": analysis_result,
            "timestamp": datetime.now().isoformat(),
            "stock_data": stock_dict
        }
        
        if request.save_to_blob:
            file_name = f"analysis/{request.stock_data.name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            local_storage.upload_json(file_name, result_data, encrypt=True)
        
        return {
            "success": True,
            "stock_name": request.stock_data.name,
            "analysis": analysis_result,
            "timestamp": datetime.now().isoformat()
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


@app.post("/api/recommend")
async def recommend_stocks(request: RecommendationRequest):
    """
    ì¢…ëª© ì¶”ì²œ
    
    Args:
        request: ì¶”ì²œ ìš”ì²­ ë°ì´í„°
        
    Returns:
        ì¶”ì²œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸
    """
    if not openai_service:
        raise HTTPException(status_code=503, detail="OpenAI ì„œë¹„ìŠ¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— Azure OpenAI ì„¤ì •ì„ ì¶”ê°€í•˜ì„¸ìš”.")
    
    try:
        # OpenAIë¥¼ í†µí•œ ì¢…ëª© ì¶”ì²œ
        preference_dict = request.user_preference.dict()
        recommendations = openai_service.recommend_stocks(preference_dict)
        
        if not recommendations:
            raise HTTPException(status_code=500, detail="ì¶”ì²œ ì‹¤íŒ¨")
        
        # ê²°ê³¼ ì €ì¥
        result_data = {
            "user_preference": preference_dict,
            "recommendations": recommendations,
            "timestamp": datetime.now().isoformat()
        }
        
        if request.save_to_blob:
            file_name = f"recommendations/{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            local_storage.upload_json(file_name, result_data, encrypt=True)
        
        return {
            "success": True,
            "recommendations": recommendations,
            "timestamp": datetime.now().isoformat()
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


@app.get("/api/storage/list")
async def list_stored_files(prefix: str = ""):
    """
    ì €ì¥ëœ íŒŒì¼ ëª©ë¡ ì¡°íšŒ
    
    Args:
        prefix: íŒŒì¼ ê²½ë¡œ ì ‘ë‘ì‚¬
        
    Returns:
        íŒŒì¼ ëª©ë¡
    """
    try:
        files = local_storage.list_files(prefix=prefix)
        return {
            "success": True,
            "files": files,
            "count": len(files)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


@app.get("/api/storage/{file_name:path}")
async def get_stored_file(file_name: str):
    """
    ì €ì¥ëœ íŒŒì¼ ì¡°íšŒ
    
    Args:
        file_name: íŒŒì¼ ì´ë¦„
        
    Returns:
        íŒŒì¼ ë‚´ìš©
    """
    try:
        content = local_storage.download_json(file_name, decrypt=True)
        if not content:
            raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return {
            "success": True,
            "data": content
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


class TrainModelRequest(BaseModel):
    model_name: str
    training_data: List[Dict[str, Any]]
    target_column: str = "target"
    save_data_file: bool = True  # í•™ìŠµ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥í• ì§€ ì—¬ë¶€


@app.post("/api/ml/train")
async def train_model(request: TrainModelRequest):
    """
    ë¡œì»¬ì—ì„œ ML ëª¨ë¸ í•™ìŠµ
    
    Args:
        request: í•™ìŠµ ìš”ì²­ ë°ì´í„°
        
    Returns:
        í•™ìŠµ ê²°ê³¼
    """
    try:
        # í•™ìŠµ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥ (ì„ íƒì‚¬í•­)
        if request.save_data_file:
            training_dir = data_dir / "training"
            training_dir.mkdir(exist_ok=True)
            
            import csv
            import json
            
            # CSV íŒŒì¼ë¡œ ì €ì¥
            csv_path = training_dir / f"{request.model_name}_training_data.csv"
            if request.training_data:
                # í”¼ì²˜ ì´ë¦„ ì¶”ì¶œ
                feature_names = [key for key in request.training_data[0].keys() if key != request.target_column]
                headers = feature_names + [request.target_column]
                
                with open(csv_path, 'w', newline='', encoding='utf-8') as f:
                    writer = csv.DictWriter(f, fieldnames=headers)
                    writer.writeheader()
                    for row in request.training_data:
                        writer.writerow(row)
            
            # JSON íŒŒì¼ë¡œë„ ì €ì¥ (ë°±ì—…)
            json_path = training_dir / f"{request.model_name}_training_data.json"
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(request.training_data, f, indent=2, ensure_ascii=False)
        
        # í”¼ì²˜ ì´ë¦„ ì¶”ì¶œ
        feature_names = None
        if request.training_data:
            feature_names = [key for key in request.training_data[0].keys() if key != request.target_column]
        
        model_path = local_ml_service.train_model(
            model_name=request.model_name,
            training_data=request.training_data,
            target_column=request.target_column,
            feature_names=feature_names
        )
        
        if not model_path:
            raise HTTPException(status_code=500, detail="ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨")
        
        model_info = local_ml_service.get_model_info(request.model_name)
        
        return {
            "success": True,
            "model_name": request.model_name,
            "model_path": model_path,
            "model_info": model_info,
            "data_saved": request.save_data_file
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


@app.post("/api/ml/predict")
async def ml_predict(model_name: str, data: Dict[str, Any]):
    """
    ML ëª¨ë¸ ì˜ˆì¸¡
    
    Args:
        model_name: ëª¨ë¸ ì´ë¦„
        data: ì˜ˆì¸¡ ë°ì´í„°
        
    Returns:
        ì˜ˆì¸¡ ê²°ê³¼
    """
    try:
        result = local_ml_service.predict(model_name, data)
        if not result:
            raise HTTPException(status_code=404, detail=f"ëª¨ë¸ '{model_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return {
            "success": True,
            **result
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


@app.get("/api/ml/models")
async def list_models():
    """ì €ì¥ëœ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ"""
    try:
        models = local_ml_service.list_models()
        models_info = []
        for model_name in models:
            info = local_ml_service.get_model_info(model_name)
            if info:
                models_info.append(info)
        
        return {
            "success": True,
            "models": models,
            "models_info": models_info,
            "count": len(models)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


@app.delete("/api/ml/models/{model_name}")
async def delete_model(model_name: str):
    """ëª¨ë¸ ì‚­ì œ"""
    try:
        success = local_ml_service.delete_model(model_name)
        if not success:
            raise HTTPException(status_code=404, detail=f"ëª¨ë¸ '{model_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        return {
            "success": True,
            "message": f"ëª¨ë¸ '{model_name}'ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ëª¨ë¸ ì‚­ì œ ì‹¤íŒ¨: {str(e)}")


class ChatRequest(BaseModel):
    message: str
    use_stock_data: bool = True


def load_csv_data_for_llm() -> list:
    """CSV íŒŒì¼ì—ì„œ ì£¼ì‹ ë°ì´í„°ë¥¼ ì§ì ‘ ë¡œë“œ"""
    stock_data = []
    
    try:
        import pandas as pd
        
        # data/training í´ë”ì—ì„œ CSV íŒŒì¼ ì°¾ê¸°
        training_path = data_dir / "training"
        csv_files = list(training_path.glob("*.csv"))
        
        # CSVê°€ ì—†ìœ¼ë©´ Excel íŒŒì¼ë„ í™•ì¸
        if not csv_files:
            excel_files = list(training_path.glob("*.xlsx"))
            if excel_files:
                latest_file = max(excel_files, key=lambda x: x.stat().st_mtime)
                df = pd.read_excel(latest_file)
            else:
                return []
        else:
            latest_file = max(csv_files, key=lambda x: x.stat().st_mtime)
            df = pd.read_csv(latest_file)
        
        stock_data = df.to_dict('records')
        print(f"âœ… ì£¼ì‹ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(stock_data)}ê°œ ì¢…ëª©")
        
    except Exception as e:
        print(f"âŒ ì£¼ì‹ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    return stock_data


def create_full_stock_context(stock_data: list) -> str:
    """LLMì´ ë¶„ì„í•  ìˆ˜ ìˆë„ë¡ ì „ì²´ ì£¼ì‹ ë°ì´í„°ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ì••ì¶• í˜•ì‹)"""
    if not stock_data:
        return ""
    
    # ì„¹í„°ë³„ë¡œ ê·¸ë£¹í™”
    sector_stocks = {}
    for stock in stock_data:
        sector = stock.get("gics_sector", stock.get("gics_sector_full", "UNKNOWN"))
        if sector not in sector_stocks:
            sector_stocks[sector] = []
        sector_stocks[sector].append(stock)
    
    context_parts = [
        f"# S&P 500 ë°ì´í„° ({len(stock_data)}ê°œ)",
        ""
    ]
    
    # ê° ì„¹í„°ë³„ ì¢…ëª© (ê°„ê²°í•œ í˜•ì‹)
    for sector, stocks in sorted(sector_stocks.items()):
        # ì‹œê°€ì´ì•¡ ìˆœ ì •ë ¬
        sorted_stocks = sorted(stocks, key=lambda x: x.get("market_cap_usd", 0) or 0, reverse=True)
        
        context_parts.append(f"## {sector} ({len(stocks)}ê°œ)")
        
        for s in sorted_stocks:
            ticker = s.get("ticker_primary", "?")
            name = s.get("name", "?")
            cap = (s.get("market_cap_usd", 0) or 0) / 1e9
            div = (s.get("dividend_yield", 0) or 0) * 100
            bucket = s.get("market_cap_bucket", "?")
            founded = s.get("founded", "?")
            div_profile = s.get("dividend_profile", "?")
            
            context_parts.append(f"{ticker}|{name}|${cap:.0f}B|{bucket}|ë°°ë‹¹{div:.1f}%|{div_profile}|ì„¤ë¦½{founded}")
        
        context_parts.append("")
    
    # ê°„ë‹¨í•œ í†µê³„
    total_cap = sum(s.get("market_cap_usd", 0) or 0 for s in stock_data) / 1e12
    avg_div = sum(s.get("dividend_yield", 0) or 0 for s in stock_data) / len(stock_data) * 100
    
    context_parts.append(f"ì´ì‹œì´: ${total_cap:.1f}T, í‰ê· ë°°ë‹¹: {avg_div:.2f}%")
    
    return "\n".join(context_parts)


@app.post("/api/chat")
async def chat_with_ai(request: ChatRequest):
    """
    AIì™€ ì±„íŒ… (CSV ë°ì´í„° ê¸°ë°˜ ì£¼ì‹ ì¶”ì²œ)
    
    Args:
        request: ì±„íŒ… ë©”ì‹œì§€
        
    Returns:
        AI ì‘ë‹µ
    """
    if not openai_service:
        raise HTTPException(status_code=503, detail="OpenAI ì„œë¹„ìŠ¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— Azure OpenAI ì„¤ì •ì„ ì¶”ê°€í•˜ì„¸ìš”.")
    
    try:
        # CSV ì£¼ì‹ ë°ì´í„° ë¡œë“œ
        stock_context = ""
        stock_count = 0
        if request.use_stock_data:
            stock_data = load_csv_data_for_llm()
            stock_count = len(stock_data)
            stock_context = create_full_stock_context(stock_data)
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = """ë‹¹ì‹ ì€ ì „ë¬¸ ì£¼ì‹ íˆ¬ì ì–´ë“œë°”ì´ì € AIì…ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ëŒ€í™”í•˜ì„¸ìš”.

ë‹¹ì‹ ì˜ ì—­í• :
1. ì œê³µëœ S&P 500 ì£¼ì‹ ë°ì´í„°ë¥¼ ì§ì ‘ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ë§ì¶¤í˜• ì¶”ì²œì„ ì œê³µí•©ë‹ˆë‹¤.
2. ì‚¬ìš©ìì˜ íˆ¬ì ì„±í–¥, ê´€ì‹¬ ë¶„ì•¼, ì˜ˆì‚°, ëª©í‘œì— ë”°ë¼ ì í•©í•œ ì¢…ëª©ì„ ì„ ë³„í•©ë‹ˆë‹¤.
3. ë°ì´í„°ì— ìˆëŠ” ì‹¤ì œ ìˆ˜ì¹˜(ì‹œê°€ì´ì•¡, ë°°ë‹¹ë¥ , ì„¤ë¦½ì—°ë„ ë“±)ë¥¼ í™œìš©í•˜ì—¬ êµ¬ì²´ì ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.
4. ì„¹í„°ë³„ ë¶„ì‚°, ì‹œê°€ì´ì•¡ ë‹¤ì–‘í™” ë“± í¬íŠ¸í´ë¦¬ì˜¤ ì „ëµë„ ì œì•ˆí•©ë‹ˆë‹¤.

ë¶„ì„ ì‹œ í™œìš©í•  ë°ì´í„° í¬ì¸íŠ¸:
- market_cap_usd: ì‹œê°€ì´ì•¡ìœ¼ë¡œ ê¸°ì—… ê·œëª¨ íŒë‹¨
- dividend_yield: ë°°ë‹¹ ìˆ˜ìµë¥ ë¡œ ì¸ì»´ íˆ¬ì ì í•©ì„± íŒë‹¨
- dividend_profile: DIV_GROWTH(ë°°ë‹¹ì„±ì¥), HIGH_YIELD(ê³ ë°°ë‹¹) ë“±
- market_cap_bucket: MEGA(ì´ˆëŒ€í˜•), LARGE(ëŒ€í˜•), MID(ì¤‘í˜•) ë“±
- gics_sector: ì„¹í„°ë³„ ë¶„ì‚° íˆ¬ì
- founded: ì„¤ë¦½ì—°ë„ë¡œ ê¸°ì—… ì•ˆì •ì„± íŒë‹¨
- date_added_to_sp500: S&P 500 í¸ì…ì¼ë¡œ ì§€ìˆ˜ í¸ì… ì´ë ¥ í™•ì¸

ì¶”ì²œ ì „ëµ:
1. ì•ˆì •í˜•: MEGA cap + ë°°ë‹¹ì„±ì¥ì£¼ + ì˜¤ë˜ëœ ê¸°ì—…
2. ì„±ì¥í˜•: IT/Healthcare + LARGE cap + ìµœê·¼ S&P í¸ì…
3. ì¸ì»´í˜•: ê³ ë°°ë‹¹ + Utilities/Financials + ë°°ë‹¹ ì§€ì†ì„±
4. ê· í˜•í˜•: ì„¹í„° ë¶„ì‚° + ì‹œê°€ì´ì•¡ ë‹¤ì–‘í™”

ì¤‘ìš”: 
- ë°˜ë“œì‹œ ì œê³µëœ ë°ì´í„°ì— ìˆëŠ” ì¢…ëª©ë§Œ ì¶”ì²œí•˜ì„¸ìš”.
- íˆ¬ì ê²°ì •ì€ ê°œì¸ì˜ ì±…ì„ì´ë©°, ì´ ì¶”ì²œì€ ì°¸ê³ ìš©ì…ë‹ˆë‹¤.
- êµ¬ì²´ì ì¸ ì¢…ëª© ì¶”ì²œ ì‹œ í‹°ì»¤ì™€ íšŒì‚¬ëª…ì„ í•¨ê»˜ ì–¸ê¸‰í•˜ì„¸ìš”."""

        if stock_context:
            system_prompt += f"\n\n{stock_context}"
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ê¸¸ì´ í™•ì¸
        print(f"ğŸ“ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(system_prompt)} ë¬¸ì")
        print(f"ğŸ“Š ì£¼ì‹ ë°ì´í„°: {stock_count}ê°œ ì¢…ëª©")
        
        # OpenAIë¥¼ í†µí•œ ì±„íŒ…
        response = openai_service.client.chat.completions.create(
            model=openai_service.deployment_name,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": request.message}
            ],
            max_completion_tokens=3000
        )
        
        ai_response = response.choices[0].message.content
        print(f"âœ… AI ì‘ë‹µ ê¸¸ì´: {len(ai_response) if ai_response else 0} ë¬¸ì")
        print(f"ğŸ“„ AI ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {ai_response[:200] if ai_response else 'None'}...")
        
        return {
            "success": True,
            "response": ai_response,
            "timestamp": datetime.now().isoformat(),
            "data_used": request.use_stock_data and bool(stock_context),
            "stocks_loaded": stock_count
        }
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"ì±„íŒ… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


if __name__ == "__main__":
    from pathlib import Path
    
    # srcì™€ scripts ë””ë ‰í† ë¦¬ë§Œ ê°ì‹œ (venv ì œì™¸)
    base_dir = Path(__file__).parent.parent
    reload_dirs = [
        str(base_dir / "src"),
        str(base_dir / "scripts"),
    ]
    
    uvicorn.run(
        "src.main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        reload_dirs=reload_dirs
    )
